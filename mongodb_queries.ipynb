{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Notebook enthält 4 Beispielabfragen, um darzustellen, wie Daten mit Hilfe von PyMongo aus einer MongoDB Datenbank abgefragt und visualisiert werden können. \n",
    "\n",
    "Im Beispielszenario werden die Gateways als Abteilungen und die Tags als Einkaufswagen definiert. Einkaufswagen sind in diesem Kontext ebenfalls als ein Proxy zur Ermittlung der Anzahl an Kunden zu sehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "from bson.objectid import ObjectId\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "client = MongoClient('mongodb+srv://' + os.getenv('MongoUser') + ':' + os.getenv('MongoPassword') + '@mongodbcluster.n6cun7v.mongodb.net/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define collection names\n",
    "db = client['MongoDB-Database']\n",
    "gateways_collection = db['gateways']\n",
    "measures_collection = db['measures']\n",
    "tags_collection = db['tags']\n",
    "\n",
    "# this color will be used in visualizations\n",
    "mongodb_green = \"#4DB33D\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abfrage 1: In welcher Abteilung halten sich die meisten Kunden auf?\n",
    "Technisch ist zur Beantwortung dieser Frage zu ermitteln, wie viele Tags sich aktuell an einem Gateway befinden.\n",
    "\n",
    "Zunächst werden über eine Pipeline die passenden Daten aus MongoDB abgerufen, bevor diese im Anschluss visualisiert werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    # stage 1: unwind the tags_assigned array\n",
    "    {\"$unwind\": \"$tags_assigned\"},\n",
    "\n",
    "    # stage 2: group by gateway_id and count the number of assigned tags\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$_id\",\n",
    "            \"gateway_id\": {\"$first\": \"$_id\"},\n",
    "            \"tag_count\": {\"$sum\": 1}\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # stage 3: sort the result by tag_count in descending order\n",
    "    {\"$sort\": {\"tag_count\": 1}},\n",
    "\n",
    "    # stage 4: project the fields for the final result\n",
    "    {\"$project\": {\"_id\": 0, \"gateway_id\": 1, \"tag_count\": 1}}\n",
    "]\n",
    "\n",
    "# execute the aggregation query\n",
    "results = list(gateways_collection.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the results to a dataframe\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# sort the dataframe by tag_count in descending order\n",
    "df_sorted = df.sort_values(by='tag_count', ascending=True)\n",
    "\n",
    "# create a horizontal bar chart\n",
    "plt.barh(df_sorted['gateway_id'], df_sorted['tag_count'], color=mongodb_green)\n",
    "plt.xlabel('Anzahl zugewiesener Tags')\n",
    "plt.ylabel('Gateway ID')\n",
    "plt.title('Anzahl Tags (Kunden) je Gateway (Abteilung)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abfrage 2: In welcher Abteilung gibt es viele Zusammenstöße mit Regalen? \n",
    "Die Raumgestaltung der einzelnen Verkaufsabteilungen erscheint ebenfalls interessant. Hohe Beschleunigungswerte werden als \"Zusammenstöße mit Regalen\" definiert. Als Grenze wurden 200 m/s² festgelegt, was etwas mehr als 20G entspricht. Die X-Achse wird als \"Vorne des Einkaufswagens\" definiert. Es werden daher lediglich die acc_x Werte visualisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    # stage 1: filter documents where acc_x is above threshold\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"acc_x\": {\"$gt\": 200}\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # stage 2: group by gateway_id and count the documents\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$gateway_id\",\n",
    "            \"count_acc_x_above_20g\": {\"$sum\": 1}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# execute the aggregation query\n",
    "results_acc_x = list(measures_collection.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results to a dataframe\n",
    "df_acc_x_above_threshold = pd.DataFrame(results_acc_x)\n",
    "\n",
    "# sort the dataframe by the count values and filter on top 5 results\n",
    "df_sorted_acc_x = df_acc_x_above_threshold.sort_values(by='count_acc_x_above_20g', ascending=False).head(5).sort_values(by='count_acc_x_above_20g', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot x data\n",
    "plt.barh(df_sorted_acc_x['_id'], df_sorted_acc_x['count_acc_x_above_20g'], color=mongodb_green)\n",
    "plt.xlabel('Count of acc_x above 20G')\n",
    "plt.ylabel('Gateway ID')\n",
    "plt.title('Top 5 Gateways with the Most acc_x Above 20G')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abfrage 3: Welche Abteilung hat das höchste Kundeninteresse? \n",
    "Im Sachzusammenhang des Einkaufens werden große Beschleunigungswerte als Stoppen und wieder Bewegen des Einkaufswagens gedeutet. Höhere durchschnittliche Beschleunigungswerte stellen somit ein höheres Kundeninteresse dar. \n",
    "\n",
    "Wie in der vorherigen Abfrage werden somit lediglich die Beschleunigungswerte in X-Achse visualisiert. Es sollen die 5 Top-Abteilungen visualisiert werden.\n",
    "\n",
    "Zunächst werden die benötigten Daten über eine passende Aggregation abgerufen. Die Daten werden im Anschluss visualisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    # stage 1: group by gateway_id and calculate average for each field\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$gateway_id\",\n",
    "            \"avg_acc_x\": {\"$avg\": \"$acc_x\"},\n",
    "            \"avg_acc_y\": {\"$avg\": \"$acc_y\"},\n",
    "            \"avg_acc_z\": {\"$avg\": \"$acc_z\"}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# execute the aggregation query\n",
    "results = list(measures_collection.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden werden die Daten visualisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results to a pandas DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Sort the DataFrame by average acceleration values and filter on top 5 results\n",
    "df_sorted_x = df.sort_values(by='avg_acc_x', ascending=False).head(5).sort_values(by='avg_acc_x', ascending=True)\n",
    "\n",
    "# Plotting horizontal bar graphs for top 5 gateways\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot for acc_x\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.barh(df_sorted_x['_id'], df_sorted_x['avg_acc_x'], color=mongodb_green)\n",
    "plt.yticks(df_sorted_x['_id'], df_sorted_x['_id'])\n",
    "plt.xlabel('Average acc_x')\n",
    "plt.title('Top 5 Gateways - Average Acceleration in X Direction')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Visualisierung erscheint es so, dass alle Top 5 Gateways identische durchschnittliche Beschleunigungswerte für die X-Achse aufweisen. Nachdem sichergestellt wurde, dass kein Problem in der Datenabfrage und dem Einladen in die Datenbank vorlag, wurde diese Auffälligkeit genauer untersucht.\n",
    "\n",
    "Zunächst wurden die durchschnittlichen Werte aller Beschleunigungswerte für alle Gateways betrachtet. Es fällt auf, dass alle Daten vollständig identisch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    gateway_id = result[\"_id\"]\n",
    "    avg_acc_x = result[\"avg_acc_x\"]\n",
    "    avg_acc_y = result[\"avg_acc_y\"]\n",
    "    avg_acc_z = result[\"avg_acc_z\"]\n",
    "    print(f\"Gateway ID: {gateway_id}, Average acc_x: {avg_acc_x}, Average acc_y: {avg_acc_y}, Average acc_z: {avg_acc_z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist zu erkennen, dass für alle Beschleunigungsrichtungen alle Durchschnittswerte identisch sind. Zur Überprüfung dieser Auffälligkeit wurde weiter die Abfrage 2 ohne Filter auf die Top-5-Gateways mit der Gesamtzahl an Measures je Gateway verglichen. Für diese weitere Abfrage musste lediglich stage 1 entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of query 2\n",
    "pipeline = [\n",
    "    # Stage 1: Filter documents where acc_x is above the threshold\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"acc_x\": {\"$gt\": 200}\n",
    "        }\n",
    "    },\n",
    "    # Stage 2: Group by gateway_id and count the documents\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$gateway_id\",\n",
    "            \"count_acc_x_above_20g\": {\"$sum\": 1}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Execute the aggregation query\n",
    "results_acc_x = list(measures_collection.aggregate(pipeline))\n",
    "\n",
    "# convert the results to a pandas DataFrame\n",
    "df_acc_x_above_threshold = pd.DataFrame(results_acc_x)\n",
    "\n",
    "# Sort the DataFrame by the count values and filter on top 5 results\n",
    "df_sorted_acc_x = df_acc_x_above_threshold.sort_values(by='count_acc_x_above_20g', ascending=False).sort_values(by='count_acc_x_above_20g', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot x data\n",
    "plt.barh(df_sorted_acc_x['_id'], df_sorted_acc_x['count_acc_x_above_20g'], color=mongodb_green)\n",
    "plt.xlabel('Count of acc_x above 20G')\n",
    "plt.ylabel('Gateway ID')\n",
    "plt.title('Gateway Measure with acc_x above 20G')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    # stage 2: group by gateway_id and count the documents\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$gateway_id\",\n",
    "            \"count_acc_x_above_20g\": {\"$sum\": 1}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# execute the aggregation query\n",
    "results_acc_x = list(measures_collection.aggregate(pipeline))\n",
    "\n",
    "# convert results to a dataframe\n",
    "df_acc_x_above_threshold = pd.DataFrame(results_acc_x)\n",
    "\n",
    "# sort the dataframe by the count values and filter on top 5 results\n",
    "df_sorted_acc_x = df_acc_x_above_threshold.sort_values(by='count_acc_x_above_20g', ascending=False).sort_values(by='count_acc_x_above_20g', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot x data\n",
    "plt.barh(df_sorted_acc_x['_id'], df_sorted_acc_x['count_acc_x_above_20g'], color=mongodb_green)\n",
    "plt.xlabel('Count of acc_x above 20G')\n",
    "plt.ylabel('Gateway ID')\n",
    "plt.title('Top 5 Gateways with the Most acc_x Above 20G')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es fällt auf, dass die Darstellungen bis auf eine abweichende X-Achse identisch sind. Das führte zur Vermutung, dass ein Muster in der Datenerstellung vorliegt. Diese Vermutung wurde untersucht, indem die Anzahl an unterschiedlichen Messungen betrachtet wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    # stage 1: group by acc_x and count documents\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$acc_x\",\n",
    "            \"count\": {\"$sum\": 1}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# execute the aggregation query\n",
    "results = list(measures_collection.aggregate(pipeline))\n",
    "\n",
    "# print the results\n",
    "for result in results:\n",
    "    acc_x = result[\"_id\"]  # Use _id directly as acc_x\n",
    "    count = result[\"count\"]\n",
    "    print(f\"acc_x: {acc_x}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist zu erkennen, dass jeder Messwert identisch häufig in den Daten vorhanden ist. Nach weiteren Unterschungen, die an dieser Stelle ausgespart werden, wurde festgestellt, dass augenscheinlich identische Daten zyklisch erstellt werden und lediglich die Gateway-Tag-Zuordnung wechselt. Das führt dazu, dass die \"Events über 20G X-Beschleunigung\" visualisiert, bis auf die X-Achse, identisch sind zur Gesamtanzahl von Measures an einem Gateway, da einige Gateway-Tag-Verbindungen mehr Measures-Zyklen durchlaufen haben als andere. Ebenfalls führt dieses zyklische Verhalten der Messwerte dazu, dass die Durchschnittswerte der Beschleunigung für alle Gateways identisch sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abfrage 4: Wie lange verbringt ein Kunde in einer Abteilung?\n",
    "Technisch ist zu ermitteln, zu welchem Zeitpunkt Gateway-Tag-Wechsel stattfinden, um anschließend die durchschnittliche Zeit einer Gateway-Tag-Verbindung zu ermitteln. Dazu sind mehrere Schritte nötig. Die unteren Schritte sind entsprechend im Code kommentiert. \n",
    "\n",
    "1. Die Daten werden abgefragt und nach recorded_time sortiert\n",
    "2. Die Differenz der recorded_time zur nun sortierten vorherigen Zeile, gruppiert nach Gateway-ID und Tag-ID, wird ermittelt\n",
    "3. Alle Differenzen, die größer als 1 Minute sind, werden als \"Connection Events\" und damit als neue Session definiert (1 in der Spalte new_connection_event)\n",
    "4. Die Spalte connection_event_group kumuliert die Summe der Connection Events, ebenfalls gruppiert nach Gateway-ID und Tag-ID. Jede connection_event_group stellt somit eine Session der Verbindung zwischen Gateway-ID und Tag-ID dar. \n",
    "5. Für jede Gruppierung aus gateway_id und connection_event_group wird eine Durchschnittszeitszeit ermittelt.\n",
    "6. Anschließend wird auf Basis dieser Session-Durchschnittszeiten die Durchschnittszeit eines Gateways ermittelt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: get and sort the data\n",
    "# define a projection to retrieve only the desired fields\n",
    "projection = {\n",
    "    \"_id\": 0,\n",
    "    \"recorded_time\": 1,\n",
    "    \"gateway_id\": 1,\n",
    "    \"tag_id\": \"$tag_address\",\n",
    "}\n",
    "\n",
    "# get documents with the specified projection\n",
    "cursor = measures_collection.find({}, projection)\n",
    "\n",
    "# convert the cursor to a list and then to a dataframe for easier handling\n",
    "measures_df = pd.DataFrame(list(cursor))\n",
    "\n",
    "# sort the dataframe by recorded_time\n",
    "measures_df.sort_values(by=\"recorded_time\", inplace=True)\n",
    "\n",
    "# step 2: calculate the time difference between consecutive records for the same tag_id and gateway_id\n",
    "measures_df[\"time_diff\"] = measures_df.groupby([\"tag_id\", \"gateway_id\"])[\"recorded_time\"].diff()\n",
    "\n",
    "# step 3: identify distinct connection events (cases where the time difference is greater than 1 minute)\n",
    "time_threshold = pd.Timedelta(minutes = 1)\n",
    "measures_df[\"new_connection_event\"] = (measures_df[\"time_diff\"] > time_threshold).astype(int)\n",
    "\n",
    "# step 4: cumulative sum of new_connection_event to create groups\n",
    "measures_df[\"connection_event_group\"] = measures_df.groupby(\"gateway_id\")[\"new_connection_event\"].cumsum()\n",
    "\n",
    "# step 5: calculate the total connection time for each gateway_id and connection_event_group\n",
    "total_connection_time = measures_df.groupby([\"gateway_id\", \"connection_event_group\"])[\"recorded_time\"].agg([\"min\", \"max\"]).reset_index()\n",
    "\n",
    "# step 6: calculate the average connection time for each gateway_id\n",
    "average_connection_time = total_connection_time.copy()\n",
    "average_connection_time[\"duration\"] = average_connection_time[\"max\"] - average_connection_time[\"min\"]\n",
    "average_connection_time[\"average_connection_time\"] = average_connection_time[\"duration\"] / pd.Timedelta(seconds=1)  # Convert to seconds for average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der Ermittlung der Durchschnittszeit, werden die Ergebnisse durch den folgenden Code-Block visualisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataframe by average_connection_time in descending order\n",
    "average_connection_time_sorted = average_connection_time.sort_values(by='average_connection_time', ascending=False)\n",
    "\n",
    "# top and bottom 5 gateways\n",
    "top5_gateways = average_connection_time_sorted.head(5).sort_values(by='average_connection_time', ascending=True)\n",
    "bottom5_gateways = average_connection_time_sorted.tail(5).sort_values(by='average_connection_time', ascending=True)\n",
    "\n",
    "# visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# top 5\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.barh(top5_gateways['gateway_id'], top5_gateways['average_connection_time'], color=mongodb_green)\n",
    "plt.yticks(top5_gateways['gateway_id'], top5_gateways['gateway_id'])\n",
    "plt.xlabel('Average Connection Time (s)')\n",
    "plt.title('Top 5 Gateways by Average Connection Time')\n",
    "\n",
    "# bottom 5\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.barh(bottom5_gateways['gateway_id'], bottom5_gateways['average_connection_time'], color=mongodb_green)\n",
    "plt.yticks(bottom5_gateways['gateway_id'], bottom5_gateways['gateway_id'])\n",
    "plt.xlabel('Average Connection Time (s)')\n",
    "plt.title('Bottom 5 Gateways by Average Connection Time')\n",
    "\n",
    "# adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Darstellung erinnert an die Darstellung der durchschnittlichen Beschleunigungswerte. Tiefere Untersuchungen dieser Auffälligkeit werden innerhalb dieses Notebooks ebenfalls ausgespart. Die obere Visualisierung ist aber ebenfalls auf ein Muster in der Datengenerierung zurückzuführen. Bei Betrachtung der genauen Werte liegen lediglich Unterschiede im Millisekundenbereich vor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_connection_time_sorted[[\"gateway_id\", \"average_connection_time\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
